{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skip\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text\n",
    "\n",
    "## Bag of words\n",
    "\n",
    "A widely used technique in NLP (natural language processing). It's a great approach to start with for any text-based problem. It's also the basis of many other more advanced methods. \n",
    "\n",
    "### Tokenization and transformation\n",
    "\n",
    "The splitting of text into pieces is known as tokenization. The most common way to split is on words, but in some cases (for example in character based langauges) you may want to split on character or split on pairs or groups of words or even something more advanced. \n",
    "\n",
    "Groups of words in a split are known as n-gram. Two or three word combinations are known as bigrams and trigrams. Bigram exmaple: 'the lazy', 'brown fox' and trigrams 'brown fox jumps', 'jumps over the'\n",
    "\n",
    "#### transformation\n",
    "\n",
    "such as reducing all letters to lower case to prevent fox and Fox counting as 2 seperate accounts. \n",
    "\n",
    "#### Stemming\n",
    "\n",
    "which strips word suffices can also be a transformation technique for extracting more signals out of different words with simiilar meanings. i.e. jump, jumping, jumps, jumped to al be expressed as jump\n",
    "\n",
    "### Vectorization\n",
    "\n",
    "After defining the dictionary you can convert any text to a set of numbers corresponding to the occurences of each dictionary word in the text. \n",
    "\n",
    "##### Stop Words\n",
    "\n",
    "words that are generally not that important or meaningless i.e. 'the', 'is', 'and'. Most ML engineers will remove the stop words and most libraries have a pre-stop word list.\n",
    "\n",
    "### Bag of words\n",
    "\n",
    "One problem with bag of words models is the nature of simple word counts. if a non-stop-word is common in the corups for example 'data'. It's not necessarily infomrative to konw that the word also appears in a new text. Instead, you'd do better by focusing on relatively rare words that are more highly predictive of the outcome of interest. \n",
    "\n",
    "To this end, it's common to scale the word counts by the inverse of the total count of that word in the corpus. Because we're describing a corpus in numbers. If there is an abundent count of a word in the training corpus but not in the new document then there is some meaning there. This means preferring rare words over common to find meaning in the differences in the rare ones. \n",
    "\n",
    "#### term frequency-inverse document frequency (tf-idf)\n",
    "\n",
    "This algo is commonly used to handle this issue. It calculates a product of the term frequency and inverses the document frequency. \n",
    "\n",
    "#### Laten semantic analysis (lsa) or latent semantic indexing (lsi)\n",
    "\n",
    "The ideas is to use the bag of word counts to build a term document matrix, with a row for each term and a column for each document. The elements of this matrix are then normalized similarly to the tf-idf process in order to avoid frequent terms dominating the power of the matrix. \n",
    "\n",
    "The value of this is there are themes or concepts that the LSA can pattern out. For example 'dog' may have related words such as 'barking', 'kennel' so on. \n",
    "\n",
    "##### singular value decomposition (SVD)\n",
    "\n",
    "you split the term document into 3 matrices (T,S,D). T is the term-concept matrix that relates the term (barking or kennel) to concepts (dog) and D is the concept document matrix that relates individual documents to concepts that you'll later use to extract the features from the LSA model. \n",
    "\n",
    "The S matrix holds the singular values. These denote the relative importance that a term has to a document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def latent_semantic_analysis(docs):\n",
    "    tfidf = TfidfVectorizer() #this uses default params\n",
    "    tfidf.fit(docs) #creates the dictionary\n",
    "    vecs = tfidf.transform(docs) #uses dictionary to vectorize documents\n",
    "    svd = TruncatedSVD(n_components=100)\n",
    "    svd.fit(vecs) #creating SVD matrices\n",
    "    return svd.transform(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24972705, -0.069432  , -0.01310874, ...,  0.02625137,\n",
       "         0.00880413,  0.02763548],\n",
       "       [ 0.1399918 , -0.07671531, -0.03975901, ..., -0.00473094,\n",
       "         0.01231183, -0.04347074],\n",
       "       [ 0.37184255, -0.04142705, -0.06709294, ..., -0.01225991,\n",
       "         0.0663855 , -0.0488487 ],\n",
       "       ..., \n",
       "       [ 0.18476811, -0.00611423, -0.08039291, ...,  0.01771869,\n",
       "        -0.01478765, -0.00509547],\n",
       "       [ 0.18795807, -0.06606652,  0.04156833, ...,  0.00142851,\n",
       "        -0.02195797, -0.03078088],\n",
       "       [ 0.08231697, -0.09080577,  0.00372698, ..., -0.02245882,\n",
       "         0.01190784, -0.01012381]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "latent_semantic_analysis(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### probailistic method (pLSA) or latent Dirichlet Analysis (LDA)\n",
    "\n",
    "LSA is based on linear algebra (math with vectors and matrices) but an equivalent analysis scan be done using probabilistic methods that model each document as a statistical mixture of topic distrubitions. \n",
    "\n",
    "The specific assumptions are made on the distribution of topics. You build an the assumption that a document can be described by a small set of topics and that ay term (word) can be attributed to a topic. In practice, LDA, can perform well on diverse datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skip\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda_model(docs):\n",
    "    #build lda model and set the number of topics to extract\n",
    "    return LdaModel(docs, num_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda_vector(lda_model, doc):\n",
    "    #gen features for a new documents\n",
    "    return lda_model[doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.utils import mock_data\n",
    "gensim_corpus = mock_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = lda_model(gensim_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Expansion\n",
    "\n",
    "#### follow links\n",
    "\n",
    "A good example of link following is establish twitter sentiment. A blob of short characters may not be enough to understand sentiment so you may follow any links that are posted with the tweet as well and expand the tweet with the text from thelink to get a better idea. \n",
    "\n",
    "#### knowledge-base expansion\n",
    "\n",
    "You could identify named entitites in the text and extend the original text with information about each named entity in an online knowledge base, think wikipedia. As you hit named entitites you would go out and grab text from a wikipedia entry and perform any of the text extraction algos on said entry.\n",
    "\n",
    "This is a non-trivial task and there are plenty of research articls out on it. \n",
    "\n",
    "#### Text meta-features\n",
    "\n",
    "This is a problem-dependent method. A tweet contains all sorts of valuable data that's particular to tweets and can be extracted for example hashtags, mentions and meta-info from twitter such as counts of retweets and favorites. \n",
    "\n",
    "For web based text, you could extract basic info form the link text such as the top level domain. \n",
    "\n",
    "## Image Features\n",
    "\n",
    "### Simple image features\n",
    "\n",
    "You make a single row with all pixels, converting the two dimensional image into one. If a color you have 3 images in one (red, blue, green channels). Normal pixel values are 0 to 1 or 0 to 255. Because of the size of modern images it can be said this process could easilly lead to overfitting\n",
    "\n",
    "### Color features\n",
    "\n",
    "If you are trying to categorize landscape images (sky, mountain, grass) it may be useful to represent by constituted colors. \n",
    "\n",
    "simple color statistics of each color channel of the image such as mean, median, mode, std deviation, skewness, kurtosis. This makes 18 features assuming a colored picture in RGB scale. 6 x 3. \n",
    "\n",
    "### Image metadata features\n",
    "\n",
    "Some meta data examples\n",
    "\n",
    "* manufacturer orientation landscape, portrait\n",
    "* date-time\n",
    "* compression jpeg, raw\n",
    "* resolution\n",
    "* aspect ratio\n",
    "* exposure time\n",
    "* aperture\n",
    "* flash \n",
    "* focal length\n",
    "\n",
    "## Extracting objects and shapes\n",
    "\n",
    "### edge detection\n",
    "\n",
    "the simplest way to represent shapes in images is to find their edges and build features on those. \n",
    "\n",
    "A few common algos\n",
    "\n",
    "* sobel\n",
    "* canny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7ec49fdb3e68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcamera\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msobel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "\n",
    "image = skimage.data.camera()\n",
    "edges = skimage.filter.sobel(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced-shape features\n",
    "\n",
    "#### Histogram of oriented Gradients (hog)\n",
    "\n",
    "1. calc the gradient image (which direction the edges of the image are 'moving')\n",
    "2. divide the image into small blocks called cells\n",
    "3. calculate the orientation of the gradients inside those cells\n",
    "4. calculate the histogram of those orientations in the individual cells\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import data, color, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skip\\Anaconda2\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.01901523,  0.01426503,  0.        , ...,  0.01419268,\n",
       "         0.01640198,  0.00489649]),\n",
       " array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.01025812, ...,  0.00111188,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.00508466,  0.        , ...,  0.        ,\n",
       "          0.00064617,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.00091809,  0.        , ...,  0.        ,\n",
       "          0.01232994,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.01886175, ...,  0.01850313,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = color.rgb2gray(skimage.data.astronaut())\n",
    "feature.hog(image, orientations=9, pixels_per_cell=(8,8), cells_per_block=(3,3), visualise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Dimensionality Reduction\n",
    "\n",
    "When performing feature extraction- dimensionality reduction should be top of mind. \n",
    "\n",
    "#### Principle Component Analysis (PCA)\n",
    "Allows you to takea  set of images and find 'typical' images that can be used as building blocks to represent the original images. Combing the first couple of principle components enables you to rebuild a large portion of the training images, whereas subsequent components will cover less-frequent patterns. \n",
    "\n",
    "These are exclusively linear algorithms. As features are generated by finding the 'distance' from a principle image.\n",
    "\n",
    "#### Automatic feature extraction\n",
    "\n",
    "Think of deep neural nets as the best way to automatically extract features. \n",
    "\n",
    "#### Time-series features\n",
    "\n",
    "##### Classical time series\n",
    "\n",
    "Is the numerical measurements that are taken over time. These are evenly spaced over time (hourly, monthly) but can have irregular data. \n",
    "\n",
    "1. value of the stock market measured hourly\n",
    "2. Day to day energy consumption of a commercial building or residential home\n",
    "3. the value, in dollars, of a client's bank account over time\n",
    "4. sets of diagnostics monitored in an industrial manufacturing plant\n",
    "\n",
    "##### Point processes\n",
    "Is a collection of events that occur over time. As opposed to measuring numerical quantities over time, these re timestamp for each discrete event that happens plus the potential of other metadata bout the event. They are commonly called event streams. \n",
    "\n",
    "1. activity of a web users, measuring the time and type of each click (clickstream data)\n",
    "2. worldwide occurences of earthquakes, hurricanes, disease outbreak and so forth\n",
    "3. individual purchases made by a customer through the history of their account\n",
    "4. event logs in a manufacturing plant, recording every time an employee touches teh system and every time a step in the manufacturing process is completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidntNum</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>PdDistrict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30203898</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>02/18/2003</td>\n",
       "      <td>16:30</td>\n",
       "      <td>NORTHERN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38261</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>04/17/2003</td>\n",
       "      <td>22:45</td>\n",
       "      <td>NORTHERN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30203901</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>02/18/2003</td>\n",
       "      <td>16:05</td>\n",
       "      <td>NORTHERN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30203923</td>\n",
       "      <td>DRUG/NARCOTIC</td>\n",
       "      <td>02/18/2003</td>\n",
       "      <td>17:00</td>\n",
       "      <td>BAYVIEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30203923</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>02/18/2003</td>\n",
       "      <td>17:00</td>\n",
       "      <td>BAYVIEW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IncidntNum        Category        Date   Time PdDistrict\n",
       "0    30203898           FRAUD  02/18/2003  16:30   NORTHERN\n",
       "1       38261        WARRANTS  04/17/2003  22:45   NORTHERN\n",
       "2    30203901   LARCENY/THEFT  02/18/2003  16:05   NORTHERN\n",
       "3    30203923   DRUG/NARCOTIC  02/18/2003  17:00    BAYVIEW\n",
       "4    30203923  OTHER OFFENSES  02/18/2003  17:00    BAYVIEW"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/sfpd_incident_all.csv\")\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Month'] = map(lambda x: datetime.strptime(\"/\".join(x.split(\"/\")[0:2]), \"%m/%y\"), df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidntNum</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30203898</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>02/18/2003</td>\n",
       "      <td>16:30</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2018-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38261</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>04/17/2003</td>\n",
       "      <td>22:45</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2017-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30203901</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>02/18/2003</td>\n",
       "      <td>16:05</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2018-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30203923</td>\n",
       "      <td>DRUG/NARCOTIC</td>\n",
       "      <td>02/18/2003</td>\n",
       "      <td>17:00</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2018-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30203923</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>02/18/2003</td>\n",
       "      <td>17:00</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2018-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IncidntNum        Category        Date   Time PdDistrict      Month\n",
       "0    30203898           FRAUD  02/18/2003  16:30   NORTHERN 2018-02-01\n",
       "1       38261        WARRANTS  04/17/2003  22:45   NORTHERN 2017-04-01\n",
       "2    30203901   LARCENY/THEFT  02/18/2003  16:05   NORTHERN 2018-02-01\n",
       "3    30203923   DRUG/NARCOTIC  02/18/2003  17:00    BAYVIEW 2018-02-01\n",
       "4    30203923  OTHER OFFENSES  02/18/2003  17:00    BAYVIEW 2018-02-01"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ts = df.groupby('Month').aggregate(len)['IncidntNum']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 14000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEKCAYAAADAVygjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrWFdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x230c2b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot time series\n",
    "plot(df_ts.index, df_ts.values, '-k', lw=2)\n",
    "xlabel('Month')\n",
    "ylabel('Number of Crimes')\n",
    "ylim((8000, 14000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
